{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "853d3288",
   "metadata": {},
   "source": [
    "CIND 820 FINAL PROJECT : Customer Churn Prediction in E-commerce and Telecommunications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b60ec",
   "metadata": {},
   "source": [
    "# ANALYSIS OF THE TELECOMMUNICATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3333796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2acbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b744773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD THE DATASET\n",
    "file_path = \"C:\\\\Users\\\\emine\\\\OneDrive\\\\Masaüstü\\\\CIND820\\\\Telco-Customer-Churn.csv\"\n",
    "df_telco = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff415e5e",
   "metadata": {},
   "source": [
    "2.1. BUILT EDA REPORT W/ RAW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42827976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset for EDA report generation\n",
    "df_raw = pd.read_csv(file_path)\n",
    "# Importing the pandas_profiling library for EDA report generation\n",
    "from pandas_profiling import ProfileReport\n",
    "# Generate a profiling report\n",
    "profile_raw = ProfileReport(df_raw, title=\"EDA Report - Raw Telco Data\", explorative=True)\n",
    "# Save the report to an HTML file\n",
    "profile_raw.to_file(\"C:/Users/emine/OneDrive/Masaüstü/CIND820/eda_telco_raw.html\")\n",
    "# COMMENT: Generates an exploratory data analysis (EDA) report for the raw dataset, providing insights into data structure, distributions, and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DISPLAY BASIC INFORMATION\n",
    "print(df_telco.info())\n",
    "print(df_telco.head())\n",
    "print(df_telco.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CHECK NUMBER OF UNIQUE VALUES PER COLUMN\n",
    "unique_values = df_telco.nunique().sort_values()\n",
    "print(\"Unique values per column:\\n\", unique_values)\n",
    "# COMMENT: Helps identify categorical vs. numerical columns, and detect constant or near-constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95171d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. DROP 'customerID' COLUMN\n",
    "df_telco.drop('customerID', axis=1, inplace=True)\n",
    "# COMMENT: 'customerID' is a unique identifier and doesn't contribute to predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b10b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CONVERT 'TotalCharges' TO NUMERIC\n",
    "df_telco['TotalCharges'] = pd.to_numeric(df_telco['TotalCharges'], errors='coerce')\n",
    "# COMMENT: Converts TotalCharges column to numeric, coercing invalid entries to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. CHECK FOR MISSING VALUES IN 'TotalCharges'\n",
    "missing_total_charges = df_telco['TotalCharges'].isnull().sum()\n",
    "print(f\"Missing TotalCharges values: {missing_total_charges}\")\n",
    "# COMMENT: Identify how many entries failed conversion and now contain NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c005288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. DROP ROWS WHERE 'TotalCharges' IS NULL\n",
    "df_telco = df_telco[df_telco['TotalCharges'].notnull()]\n",
    "# COMMENT: Dropping a small number of missing rows is preferable to imputation in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. CONVERT 'Churn' TO BINARY\n",
    "df_telco['Churn'] = df_telco['Churn'].map({'No': 0, 'Yes': 1})\n",
    "# COMMENT: Converts target variable into binary format for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f968120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. CONFIRM DATA CLEANING\n",
    "print(df_telco.info())\n",
    "print(df_telco['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be93101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. ENCODING\n",
    "# Identify categorical columns for encoding\n",
    "cat_cols = df_telco.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Encoding: Derive ContractLength from the 'Contract' feature\n",
    "contract_map = {'Month-to-month': 1, 'One year': 12, 'Two year': 24}\n",
    "df_telco['ContractLength'] = df_telco['Contract'].map({'Month-to-month': 0, 'One year': 1, 'Two year': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now encode all categorical variables\n",
    "df_encoded = pd.get_dummies(df_telco, columns=cat_cols, drop_first=True)\n",
    "# COMMENT: One-hot encoding converts categorical variables into binary columns, allowing them to be used in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. SPLIT\n",
    "X = df_encoded.drop(\"Churn\", axis=1)\n",
    "y = df_encoded[\"Churn\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d191dcf",
   "metadata": {},
   "source": [
    "13. FEATURE ENGINEERING (apply directly to X_train and X_test, NOT df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be82d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
    "# Create new features based on existing ones\n",
    "X_train['IsLongTermCustomer'] = (X_train['tenure'] > 24).astype(int)\n",
    "X_train['HighMonthlyChargeFlag'] = (X_train['MonthlyCharges'] > 70).astype(int)\n",
    "X_train['TotalChargesPerMonth'] = X_train['TotalCharges'] / X_train['tenure'].replace(0, np.nan)\n",
    "X_train['TotalChargesPerMonth'] = X_train['TotalChargesPerMonth'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2aac7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Apply the same feature engineering to the test set\n",
    "X_test['IsLongTermCustomer'] = (X_test['tenure'] > 24).astype(int)\n",
    "X_test['HighMonthlyChargeFlag'] = (X_test['MonthlyCharges'] > 70).astype(int)\n",
    "X_test['TotalChargesPerMonth'] = X_test['TotalCharges'] / X_test['tenure'].replace(0, np.nan)\n",
    "X_test['TotalChargesPerMonth'] = X_test['TotalChargesPerMonth'].fillna(0)\n",
    "X_test['ContractLength'] = df_telco.loc[X_test.index, 'Contract'].map(contract_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.1 PCA FOR DIMENSIONALITY REDUCTION (Train Set Only to Avoid Leakage)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43499f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA is now based only on training data\n",
    "features = X_train.copy()\n",
    "target = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA DataFrame\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['Churn'] = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Churn', palette='coolwarm', alpha=0.6)\n",
    "plt.title(\"PCA - Customer Churn Visualization (Train Set Only)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained Variance\n",
    "print(f\"Explained Variance by PC1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"Explained Variance by PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "# COMMENT: PCA reduces dimensionality while retaining variance, helping visualize customer churn patterns in a 2D space. The first two principal components explain a significant portion of the variance, allowing for effective visualization of churn clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d16ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.2. GENERATE EDA REPORT FOR ENCODED DATA\n",
    "profile_clean = ProfileReport(df_encoded, title=\"EDA Report - Cleaned Telco Data\", explorative=True)\n",
    "profile_clean.to_file(\"C:/Users/emine/OneDrive/Masaüstü/CIND820/eda_telco_cleaned.html\")\n",
    "# COMMENT: Generates an EDA report for the cleaned and encoded dataset, providing insights into feature distributions, correlations, and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c65ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. ENGAGEMENT SCORE (Bundled Services Index)\n",
    "# Identify bundled features\n",
    "bundled_features = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                    'TechSupport', 'StreamingTV', 'StreamingMovies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns that match bundled features\n",
    "bundled_cols = [col for col in df_encoded.columns if any(f\"{f}_Yes\" in col for f in bundled_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reindex X_train and X_test to include only bundled columns, filling missing ones with 0\n",
    "X_train_engaged = X_train.reindex(columns=bundled_cols, fill_value=0)\n",
    "X_test_engaged = X_test.reindex(columns=bundled_cols, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6844b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EngagementScore as the sum of active bundled services\n",
    "X_train['EngagementScore'] = X_train_engaged.sum(axis=1)\n",
    "X_test['EngagementScore'] = X_test_engaged.sum(axis=1)\n",
    "# COMMENT: EngagementScore is a new feature that quantifies how many value-added digital services (security, support, streaming) a customer uses.\n",
    "# Higher scores may signal greater customer retention due to stronger integration with the service ecosystem.EngagementScore = Sum of value-added digital service usage flags.\n",
    "# Reindex ensures same features used in both train and test, avoiding structural mismatch and target leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.1. CHECK ENGAGEMENT SCORE DISTRIBUTION\n",
    "print(\"Engagement Score Distribution (Train Set):\")\n",
    "print(X_train['EngagementScore'].value_counts().sort_index())\n",
    "# COMMENT: This distribution shows how many bundled services customers typically use. Most customers use 2-3 services, with fewer using all 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.1. VISUALIZE ENGAGEMENT SCORE DISTRIBUTION FOR INTERPRETATION\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(X_train['EngagementScore'], bins=7, kde=False, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Engagement Score (Train Set)\")\n",
    "plt.xlabel(\"Number of Active Digital Services\")\n",
    "plt.ylabel(\"Customer Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# COMMENT: This histogram shows the distribution of Engagement Scores, indicating how many bundled services customers typically use. Most customers use 2-3 services, with fewer using all 6.\n",
    "# COMMENT: EngagementScore quantifies how many value-added digital services (security, support, streaming) a customer uses. \n",
    "# Higher scores may signal greater customer retention due to stronger integration with the service ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.2. CHURN RATE DISTRUBITION BY ENGAGEMENT SCORE\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=y_train, y=X_train['EngagementScore'], palette='pastel')\n",
    "plt.title(\"Engagement Score by Churn Status\")\n",
    "plt.xlabel(\"Churn (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Engagement Score\")\n",
    "plt.xticks([0, 1], ['Non-Churn', 'Churn'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4af848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.3. CHECK AVERAGE ENGAGEMENT SCORE FOR CHURNED AND NON-CHURNED CUSTOMERS\n",
    "# Calculate mean EngagementScore using training set only\n",
    "mean_engaged_churn = X_train[y_train == 1]['EngagementScore'].mean()\n",
    "mean_engaged_nonchurn = X_train[y_train == 0]['EngagementScore'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average EngagementScore (Churned): {mean_engaged_churn:.2f}\")\n",
    "print(f\"Average EngagementScore (Non-Churned): {mean_engaged_nonchurn:.2f}\")\n",
    "# COMMENT: The average EngagementScore shows that churned customers use fewer bundled digital services compared to non-churned ones.\n",
    "# COMMENT: Calculating these averages from the training set ensures no data leakage while still revealing meaningful patterns.\n",
    "#COMMENT: Churned customers had a noticeably lower average engagement score (1.80) compared to retained ones (2.13), suggesting that reduced customer-platform interaction is associated with higher churn risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.4 EDA VISUALS FOR NUMERICAL DISTRIBUTIONS\n",
    "num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.histplot(df_telco[col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98185c",
   "metadata": {},
   "source": [
    "COMMENT: Visualizes the distribution of key numerical features, helping to spot skewness or multimodal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704dafd3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 15. CATEGORICAL FEATURE DISTRIBUTION BY CHURN\n",
    "cat_eda_cols = ['InternetService', 'Contract', 'PaymentMethod']\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, col in enumerate(cat_eda_cols):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    sns.countplot(data=df_telco, x=col, hue='Churn')\n",
    "    plt.title(f\"{col} by Churn\")\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f6352",
   "metadata": {},
   "source": [
    "COMMENT: Reveals relationships between churn and key categorical features through side-by-side bar plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f69e1",
   "metadata": {},
   "source": [
    "15.1. CHURN RATE BY SERVICE TYPE (Contract, TechSupport, OnlineSecurity, InternetService)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfce63b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def churn_rate_by_category(df, column):\n",
    "    churn_pct = pd.crosstab(df[column], df['Churn'], normalize='index') * 100\n",
    "    churn_pct = churn_pct.rename(columns={0: 'Non-Churn %', 1: 'Churn %'})\n",
    "\n",
    "    # Visualization\n",
    "    churn_pct['Churn %'].plot(kind='bar', figsize=(8, 5), color='salmon', edgecolor='black')\n",
    "    plt.title(f\"Churn Rate by {column}\")\n",
    "    plt.ylabel(\"Churn Percentage\")\n",
    "    plt.xlabel(column)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nChurn Percentage by {column}:\\n\", churn_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fade461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for selected features\n",
    "for col in ['Contract', 'TechSupport', 'OnlineSecurity', 'InternetService']:\n",
    "    churn_rate_by_category(df_telco, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c6990",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "COMMENT: This function calculates churn rates for a given categorical feature and visualizes the results, providing insights into how different categories relate to churn.\n",
    "COMMENT: This analysis shows how different service features impact churn rates, providing actionable insights for customer retention strategies.\n",
    "Contract : Customers with Month-to-month contracts exhibit a significantly higher churn rate (over 40%) compared to those on One year or Two year plans. This suggests that long-term commitment correlates with reduced churn, potentially due to early termination fees or perceived service satisfaction.\n",
    "TechSupport : Churn is notably higher among customers who do not have Tech Support services. The presence of technical support likely enhances customer retention by resolving issues quickly and improving user experience.\n",
    "OnlineSecurity : Similar to TechSupport, customers without OnlineSecurity are more prone to churn. This may reflect lower engagement levels or unmet expectations regarding bundled service value.\n",
    "InternetService : Among the InternetService categories, Fiber optic users have the highest churn rate—likely due to higher costs or competitive alternatives. DSL users show lower churn, and those with No internet service churn the least, possibly reflecting minimal telecom engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. CROSSTABS FOR CHURN\n",
    "cat_features_to_check = ['Contract', 'InternetService', 'PaymentMethod', 'OnlineSecurity', 'TechSupport']\n",
    "print(\"\\nChurn Crosstab (% by Category)\\n\")\n",
    "for col in cat_features_to_check:\n",
    "    if col in df_telco.columns:\n",
    "        print(f\"\\n{col} vs Churn\")\n",
    "        cross = pd.crosstab(df_telco[col], df_telco['Churn'], normalize='index') * 100\n",
    "        print(cross.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28893565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17.ANOVA TESTS FOR NUMERICAL FEATURES ACROSS CATEGORICAL FEATURES\n",
    "#Import necessary libraries(f_oneway is the one-way ANOVA function from SciPy.)\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf699160",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- ANOVA TEST RESULTS ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821963a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MonthlyCharges across InternetService\n",
    "groups1 = [df_telco[df_telco['InternetService'] == cat]['MonthlyCharges'] for cat in df_telco['InternetService'].unique()]\n",
    "f1, p1 = f_oneway(*groups1)\n",
    "print(f\"MonthlyCharges by InternetService - F: {f1:.4f}, p: {p1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb199c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalCharges across Contract\n",
    "groups2 = [df_telco[df_telco['Contract'] == cat]['TotalCharges'] for cat in df_telco['Contract'].unique()]\n",
    "f2, p2 = f_oneway(*groups2)\n",
    "print(f\"TotalCharges by Contract - F: {f2:.4f}, p: {p2:.4f}\")\n",
    "##COMMENT:This code performs ANOVA tests to see if there are statistically significant differences in charges across different customer groups:\n",
    "#MonthlyCharges by InternetService→ Tests if average monthly charges differ by Internet type (e.g., DSL, Fiber, No service).\n",
    "#TotalCharges by Contract→ Tests if total charges differ by contract type (e.g., Month-to-month, One year, Two year).If the p-value < 0.05, it means there's a significant difference between the groups.\n",
    "#This test is both meaningful and contributes to reporting in terms of understanding the indirect effect of pricing on churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c2816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. CORRELATION ANALYSIS\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Churn', data=df_telco)\n",
    "plt.title(\"Churn Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. SHAPIRO-WILK NORMALITY TEST\n",
    "from scipy.stats import shapiro\n",
    "for col in ['tenure', 'MonthlyCharges', 'TotalCharges']:\n",
    "    stat, p = shapiro(df_telco[col])\n",
    "    print(f\"{col} - p-value: {p:.4f}\")\n",
    "##COMMENT:\"Shapiro-Wilk test indicated that tenure and TotalCharges are not normally distributed (p < 0.05), justifying the use of tree-based models like Random Forest.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. OUTLIER ANALYSIS - Z-SCORE\n",
    "from scipy.stats import zscore\n",
    "z_scores = df_telco[['tenure', 'MonthlyCharges', 'TotalCharges']].apply(zscore)\n",
    "print(\"Outlier counts:\")\n",
    "print((z_scores > 3).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.1. OUTLIER VISUALIZATION - BOX PLOTS\n",
    "plt.figure(figsize=(15, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(['tenure', 'MonthlyCharges', 'TotalCharges']):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.boxplot(x=df_telco[col], color='skyblue')\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.xlabel(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4701150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#COMMENT:Boxplots and Z-score-based scatter plots reveal the presence of outliers particularly in TotalCharges and MonthlyCharges. These may indicate customers with extreme usage or billing behaviors and could influence model training. Outlier handling (e.g., capping, removal, or robust scaling) may be considered in future modeling stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ce70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. CHI-SQUARE TEST FOR CATEGORICAL FEATURES\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "# Imports this function that performs the Chi-square test of independence to determine whether two categorical variables are significantly associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f368f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    cont_table = pd.crosstab(df_telco[col], df_telco['Churn'])\n",
    "    chi2, p, dof, ex = chi2_contingency(cont_table)\n",
    "    chi2_results.append((col, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53eb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME FOR CHI-SQUARE RESULTS\n",
    "chi2_df = pd.DataFrame(chi2_results, columns=['Feature', 'p_value'])\n",
    "chi2_df = chi2_df.sort_values(by='p_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a54290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE SIGNIFICANT FEATURES P-VALUES < 0.05\n",
    "sig_features = chi2_df[chi2_df['p_value'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW SIGNIFICANT FEATURES\n",
    "sig_features = chi2_df[chi2_df['p_value'] < 0.05].copy()\n",
    "sig_features['-log10(p-value)'] = -np.log10(sig_features['p_value'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sig_features['Feature'], sig_features['-log10(p-value)'])\n",
    "plt.xlabel(\"-log10(p-value)\")\n",
    "plt.title(\"Chi-Square Test: Feature Significance for Churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "##COMMENT:Statistical tests conducted on both numerical and categorical variables have revealed significant relationships between churn (customer loss) and many variables. In particular, variables such as Contract, InternetService, and PaymentMethod stand out as decisive factors in understanding customer loss. These variables must definitely be taken into account in the subsequent modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. SCALING NUMERICAL FEATURES\n",
    "scaler = StandardScaler()\n",
    "df_encoded[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(\n",
    "    df_encoded[['tenure', 'MonthlyCharges', 'TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896c49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. MULTICOLLINEARITY ANALYSIS (VIF)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vif = df_encoded.select_dtypes(include=['float64', 'int64']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84edfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"Feature\"] = X_vif.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ff923",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = vif_df[vif_df[\"VIF\"] > 5]\n",
    "print(\"\\n Top 15 features with highest VIF values:\")\n",
    "print(vif_df.sort_values(by=\"VIF\", ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c58d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE TOP 15 FEATURES WITH HIGHEST VIF\n",
    "top_vif = vif_df.sort_values(by=\"VIF\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da623cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE TOP 15 FEATURES WITH HIGHEST VIF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_vif[\"Feature\"], top_vif[\"VIF\"])\n",
    "plt.xlabel(\"VIF Value\")\n",
    "plt.title(\"Top 15 Features with Highest VIF (Multicollinearity)\")\n",
    "plt.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# INTERPRETATION COMMENT: The VIF analysis indicates potential multicollinearity issues among several features, particularly those related to internet service types and payment methods. Features like \"Fiber optic internet service\" and \"Electronic check payment method\" show high VIF values, suggesting redundancy in information. This could lead to instability in model coefficients and inflated standard errors. Addressing multicollinearity may involve removing or combining features, or using regularization techniques in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. CORRELATION HEATMAP\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = df_encoded.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe7f81",
   "metadata": {},
   "source": [
    "#COMMENT: Correlation heatmap allows quick detection of redundant features or strong linear relationships.\n",
    "#COMMENT: The heatmap illustrates the linear correlations between numerical features in the Telco churn dataset. Notably, there is a strong positive correlation between tenure and TotalCharges, as well as between MonthlyCharges and TotalCharges, indicating that customers who stay longer or pay more monthly tend to accumulate higher total charges. However, the Churn variable shows weak correlations with most features, suggesting that churn behavior may not be directly explained by linear relationships alone. This highlights the importance of using advanced modeling techniques, such as logistic regression or SHAP, to uncover more complex patterns behind customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24.1. TARGET-CORRELATION VISUALIZATION\n",
    "target_corr = corr['Churn'].sort_values(ascending=False)[1:11]  # exclude self-correlation\n",
    "plt.figure(figsize=(8, 6))\n",
    "target_corr.plot(kind='barh')\n",
    "plt.title(\"Top 10 Features Most Correlated with Churn\")\n",
    "plt.xlabel(\"Correlation with Churn\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# COMMENT: The bar chart shows the top features most linearly correlated with churn, yet all exhibit very weak correlations. For example, tenure has a slightly positive correlation, implying customers who stay longer are marginally less likely to churn, while MonthlyCharges and SeniorCitizen have small negative correlations, suggesting higher monthly costs or being a senior might slightly increase churn risk. However, the extremely low absolute values indicate that no single numeric feature strongly drives churn on its own, reinforcing the need for non-linear modeling approaches to better capture underlying churn dynamics.\n",
    "# COMMENT: Highlights which features are most associated with churn—useful for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. RANDOM FOREST CLASSIFIER ANALYSIS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.1. SPLIT DATA AND APPLY SMOTE\n",
    "start_split = time.time()\n",
    "X = df_encoded.drop(\"Churn\", axis=1)\n",
    "y = df_encoded[\"Churn\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "end_split = time.time()\n",
    "print(f\" Train-test split time: {end_split - start_split:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.2. RANDOM FOREST TRAINING\n",
    "start_train_rf = time.time()\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "end_train_rf = time.time()\n",
    "print(f\" Training time for Random Forest: {end_train_rf - start_train_rf:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.3. PREDICTION\n",
    "start_pred_rf = time.time()\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "end_pred_rf = time.time()\n",
    "print(f\" Prediction time for Random Forest: {end_pred_rf - start_pred_rf:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2709ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.4. PERFORMANCE METRICS\n",
    "print(\"\\nClassification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_rf))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", matthews_corrcoef(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe2f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.5. CONFUSION MATRIX\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.6. ROC CURVE\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f\"AUC = {roc_auc_score(y_test, y_prob_rf):.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Random Forest\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a065e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.7. FEATURE IMPORTANCE\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "top_features = importances.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 20 Important Features from Random Forest:\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d12965",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "top_features.plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Top 20 Important Features from Random Forest\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.8. SMOTE CLASS DISTRIBUTION PLOT\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_resampled, palette=\"Set2\")\n",
    "plt.title(\"Churn Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25.9. CROSS-VALIDATION SCORE WITH RANDOM FOREST\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_cv = RandomForestClassifier(random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf_cv, X, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forest CV ROC AUC Scores:\", rf_cv_scores)\n",
    "print(\"Mean CV ROC AUC (RF):\", np.mean(rf_cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(rf_cv_scores))\n",
    "print(\"Score Range:\", np.min(rf_cv_scores), \"to\", np.max(rf_cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c98c3",
   "metadata": {},
   "source": [
    "COMMENT: The Random Forest model was trained on a balanced dataset using SMOTE. \n",
    "It achieved consistent ROC AUC scores in both test evaluation and cross-validation.\n",
    "Feature importance and MCC values provide additional model transparency for business use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. LOGISTIC REGRESSION CLASSIFIER ANALYSIS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.1. INITIALIZE AND TRAIN MODEL\n",
    "start_train_log = time.time()\n",
    "log_model = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "log_model.fit(X_train_resampled, y_train_resampled)\n",
    "end_train_log = time.time()\n",
    "print(f\" Training time for Logistic Regression: {end_train_log - start_train_log:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee968a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.2.PREDICTION FOR LOGISTIC REGRESSION TIMING\n",
    "start_pred_log = time.time()\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "y_prob_log = log_model.predict_proba(X_test)[:, 1]\n",
    "end_pred_log = time.time()\n",
    "print(f\" Prediction time for Logistic Regression: {end_pred_log - start_pred_log:.2f} seconds\")\n",
    "# COMMENT: The Logistic Regression model is trained on the resampled training set to predict customer churn, and its performance is evaluated using accuracy, ROC AUC, and confusion matrix metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad615aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.3. PERFORMANCE METRICS\n",
    "print(\"\\nClassification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy (Logistic Regression):\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"ROC AUC Score (Logistic Regression):\", roc_auc_score(y_test, y_prob_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.4. CONFUSION MATRIX\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_log, annot=True, fmt='d', cmap='Purples')\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ad1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.5. ROC CURVE\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_log, tpr_log, label=f\"AUC = {roc_auc_score(y_test, y_prob_log):.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.6. COEFFICIENTS (Feature Impact)\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': log_model.coef_[0]\n",
    "}).sort_values(by='Coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff54121",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop Features Influencing Churn (Logistic Regression):\")\n",
    "print(coefficients.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "coefficients.set_index('Feature').sort_values(by='Coefficient', ascending=True).tail(20).plot(kind='barh')\n",
    "plt.title(\"Top Influential Features - Logistic Regression Coefficients\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.7. CROSS-VALIDATION SCORE WITH LOGISTIC REGRESSION\n",
    "# Instantiate logistic regression model\n",
    "baseline_model = LogisticRegression(max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265718a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation using ROC AUC as the scoring metric\n",
    "lr_cv_scores = cross_val_score(baseline_model, X, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb3639",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print the individual and summary stats\n",
    "print(\"\\nLogistic Regression CV ROC AUC Scores:\", lr_cv_scores)\n",
    "print(\"Mean CV ROC AUC:\", np.mean(lr_cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(lr_cv_scores))\n",
    "print(\"Score Range:\", np.min(lr_cv_scores), \"to\", np.max(lr_cv_scores))\n",
    "# COMMENT: The Logistic Regression model achieved consistent cross-validation ROC AUC scores ranging from 0.8401 to 0.8480, with an average of 0.8449. This indicates strong and stable discriminative performance across folds, making it a robust and interpretable model for predicting customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. MODEL PERFORMANCE COMPARISON TABLE\n",
    "# Metric values – replace these with your actual model scores if needed\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_auc = roc_auc_score(y_test, y_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e01da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_accuracy = accuracy_score(y_test, y_pred_log)\n",
    "log_auc = roc_auc_score(y_test, y_prob_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07704482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS FOR RANDOM FOREST\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007104aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS FOR LOGISTIC REGRESSION\n",
    "log_precision = precision_score(y_test, y_pred_log)\n",
    "log_recall = recall_score(y_test, y_pred_log)\n",
    "log_f1 = f1_score(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table with detailed metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression'],\n",
    "    'Accuracy': [rf_accuracy, log_accuracy],\n",
    "    'ROC AUC': [rf_auc, log_auc],\n",
    "    'Precision': [rf_precision, log_precision],\n",
    "    'Recall': [rf_recall, log_recall],\n",
    "    'F1-score': [rf_f1, log_f1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09eea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE COMPARISON TABLE\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.table(\n",
    "    cellText=comparison_df.round(3).values,\n",
    "    colLabels=comparison_df.columns,\n",
    "    loc='center',\n",
    "    cellLoc='center'\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.title(\"Model Performance Comparison (Accuracy, AUC, Precision, Recall, F1)\", pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae38b9",
   "metadata": {},
   "source": [
    "#COMMENT: This table summarizes the performance of both models, highlighting their strengths in terms of accuracy, ROC AUC, precision, recall, and F1-score.\n",
    "#COMMENT:    |MODEL|---------------|Accuracy|---|ROC AUC|\n",
    "            |Random Forest|---------|0.773|-----|0.817|\n",
    "            |Logistic Regression|---|0.763|-----|0.831|\n",
    "# While the Random Forest model offers slightly better classification accuracy, the Logistic Regression model shows stronger performance in discriminative power (as evidenced by its higher ROC AUC). This makes Logistic Regression a strong candidate when interpretability and ranking quality are critical, despite its slightly lower accuracy. On the other hand, Random Forest provides more robust predictions and handles nonlinearities and interactions better.Depending on the business objective — whether prioritizing interpretability or maximum predictive accuracy — both models present valuable and complementary insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff1fa",
   "metadata": {},
   "source": [
    "#INTERPRETATION ABOUT SHAP PLOTS:In the Telco dataset analysis, both Logistic Regression and Random Forest models were implemented to predict customer churn. While SHAP (SHapley Additive exPlanations) is a powerful tool for model interpretability, it was not applied to the Telco models for the following reasons:\n",
    "Logistic Regression already provides inherent interpretability through model coefficients. Since the relationship between features and the target is linear, the direction and strength of influence can be directly interpreted from the regression output without needing post-hoc tools like SHAP.\n",
    "Random Forest, although non-linear, was evaluated using feature importance scores, which offered sufficient insight into the key drivers of churn. Additionally, preliminary SHAP attempts resulted in dimensional mismatches due to encoding and resampling inconsistencies, and fixing them required additional complexity that did not yield substantially improved interpretability.\n",
    "Therefore, to maintain model clarity and analytical focus, SHAP was only utilized for the e-commerce dataset, where more complex models like XGBoost were employed and interpretability was essential due to higher feature interactions.\n",
    "# COMMENT: Including precision, recall, and F1-score provides a more comprehensive view of model performance, especially for imbalanced datasets like churn.\n",
    "These metrics help assess not just overall accuracy but also how well the model identifies true positives and avoids false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189642e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27.1. SHAP ANALYSIS FOR RANDOM FOREST MODEL\n",
    "# Stratified Sample for SHAP Analysis\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, stratify=y_train_resampled,\n",
    "    test_size=(len(X_train_resampled) - 500), random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70325ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = X_sample.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb035d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Explainer \n",
    "explainer = shap.Explainer(rf_model, X_sample)\n",
    "shap_values = explainer(X_sample)           # shape: (500, 31, 2)\n",
    "shap_class_1 = shap_values[..., 1]          # churn = 1 SHAP values\n",
    "shap.plots.beeswarm(shap_class_1)           # Visualize SHAP values for class 1 (churn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf77f3e",
   "metadata": {},
   "source": [
    "INTERPRETATION:According to the SHAP summary plot, the most influential factor in predicting customer churn is tenure, with shorter customer lifespans (low tenure values) significantly increasing the likelihood of churn. Customers with longer tenure appear more loyal and are less likely to leave. Fiber optic internet service is another major contributor to churn; customers using this service type tend to churn more frequently, possibly due to pricing or service expectations. Contract length also plays a key role—longer contracts strongly reduce churn risk, suggesting that contract-based retention strategies are effective. Additionally, higher monthly charges slightly increase churn probability, while lower total charges—often associated with new customers—also correspond to higher churn risk. These insights suggest that newer customers and those with higher bills are more at risk, and that structured contracts and customer loyalty should be key focuses for churn prevention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28. RANDOM FOREST DECISION TREE VISUALIZATION\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(rf_model.estimators_[0], feature_names=X_train_resampled.columns, filled=True, max_depth=3, fontsize=10)\n",
    "plt.title(\"Random Forest - First Tree Visualization (Depth=3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e5f35",
   "metadata": {},
   "source": [
    "COMMENT: This decision tree shows how the Random Forest model splits on features like ContractLength, TotalCharges, StreamingTV, and PaymentMethod to distinguish churn vs. non-churn.\n",
    "Customers with short contract lengths, low total charges, and specific service patterns are more likely to churn.\n",
    "On the other hand, customers with longer contracts and consistent payment histories are less likely to churn.\n",
    "Visualizing one tree helps interpret how the ensemble makes its decisions in a human-readable form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1431cee",
   "metadata": {},
   "source": [
    "WHY THE MODEL PREDICTS CHURN:\n",
    "- ContractLength ≤ 0.5 → short-term (month-to-month) customers are more churn-prone.\n",
    "- No StreamingTV or StreamingMovies suggests low engagement.\n",
    "- PaymentMethod_Electronic check users have higher churn risk.\n",
    "- Customers with low tenure (new customers) tend to churn more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9a6a0",
   "metadata": {},
   "source": [
    "WHY THE MODEL PREDICTS NON-CHURN:\n",
    "- Longer contracts, high TotalCharges (longer relationship), stable payment method.\n",
    "- Dependents and bundled services (TV, internet) increase customer stickiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56626051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28.1. PRECISION-RECALL CURVE\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b852313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a600d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take class predictions and probabilities scores\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]  # Class 1 için (churn) olasılık skorları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6cdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision, Recall, and Thresholds\n",
    "precision_vals, recall_vals, threshold_vals = precision_recall_curve(y_test, y_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Precision-Recall Curve\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(threshold_vals, precision_vals[:-1], label='Precision', linestyle='--')\n",
    "plt.plot(threshold_vals, recall_vals[:-1], label='Recall', linestyle='-')\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision vs. Recall Curve (Random Forest)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fdbef5",
   "metadata": {},
   "source": [
    "COMMENT: The Precision-Recall curve illustrates the trade-off between precision and recall at various classification thresholds.\n",
    "It helps identify the optimal threshold based on business priorities, such as whether to prioritize precision (\n",
    "COMMENT: This curve visually demonstrates the trade-off between precision and recall across different thresholds, aiding in threshold selection based on business priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28.2. MODEL COMPARISON TABLE\n",
    "# CURRENT PERFORMANCE METRICS\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
    "    'Accuracy': [0.773, 0.763, 0.755],\n",
    "    'ROC AUC': [0.817, 0.831, 0.805],\n",
    "    'F1-score': [0.69, 0.64, 0.67]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552ee87",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# PERFORMANCE COMPARISON TABLE\n",
    "plt.figure(figsize=(7, 3.5))\n",
    "plt.table(cellText=comparison_df.round(3).values,\n",
    "          colLabels=comparison_df.columns,\n",
    "          loc='center', cellLoc='center')\n",
    "plt.axis('off')\n",
    "plt.title(\"Model Performance Comparison (Accuracy, AUC, F1-score)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# COMMENT: This table summarizes the performance metrics of the Random Forest, Logistic Regression, and XGBoost models, allowing for quick comparison of their predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. XGBOOST MODEL (ADDITIONAL MODEL) + TIMING\n",
    "start_train_xgb = time.time()\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "end_train_xgb = time.time()\n",
    "print(f\" Training time for XGBoost: {end_train_xgb - start_train_xgb:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.1.PREDICTION WITH XGBOOST + TIMING\n",
    "start_pred_xgb = time.time()\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "end_pred_xgb = time.time()\n",
    "print(f\" Prediction time for XGBoost: {end_pred_xgb - start_pred_xgb:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91371b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBABILITIES\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.2.METRICS\n",
    "print(\"\\nXGBoost Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_xgb))\n",
    "print(\"Matthews Correlation Coefficient (XGBoost):\", matthews_corrcoef(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35932d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.3.ROC CURVE FOR XGBOOST\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f\"AUC = {roc_auc_score(y_test, y_prob_xgb):.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - XGBoost\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# COMMENT: The XGBoost model is trained on the resampled training set to predict customer churn, and its performance is evaluated using accuracy, ROC AUC, and confusion matrix metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.4.CONFUSION MATRIX FOR XGBOOST\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - XGBoost\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686edaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29.5. CROSS-VALIDATION SCORE WITH XGBOOST\n",
    "# Define StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d387ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86af08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "xgb_cv_scores = cross_val_score(xgb, X, y, cv=cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c985b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed results\n",
    "print(\"XGBoost CV ROC AUC Scores:\", xgb_cv_scores)\n",
    "print(\"Mean CV ROC AUC (XGB):\", np.mean(xgb_cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(xgb_cv_scores))\n",
    "print(\"Score Range:\", np.min(xgb_cv_scores), \"to\", np.max(xgb_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30. HYPERPARAMETER TUNING WITH GRIDSEARCHCV FOR XGBOOST\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETER GRID FOR XGBOOST\n",
    "# This grid defines the hyperparameters to be tuned for the XGBoost model.\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfae95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCRIBE BASE XGBOOST MODEL\n",
    "xgb_base = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e23d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCHCV\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNING\n",
    "grid_xgb.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "# The best parameters from GridSearchCV are printed to understand the optimal settings for the XG\n",
    "print(\"Best Parameters for XGBoost:\", grid_xgb.best_params_)\n",
    "print(\"Best ROC AUC:\", grid_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc43a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30.1. OPTIMIZED XGBOOST MODEL WITH BEST PARAMETERS\n",
    "# The best parameters from GridSearchCV are used to create the optimized XGBoost model.\n",
    "# BEST MODEL\n",
    "best_xgb = grid_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c820503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)\n",
    "y_prob_best_xgb = best_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS\n",
    "print(\"\\nOptimized XGBoost Report:\")\n",
    "print(classification_report(y_test, y_pred_best_xgb))\n",
    "print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_best_xgb))\n",
    "print(\"Optimized ROC AUC:\", roc_auc_score(y_test, y_prob_best_xgb))\n",
    "print(\"Optimized MCC:\", matthews_corrcoef(y_test, y_pred_best_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE\n",
    "fpr_best_xgb, tpr_best_xgb, _ = roc_curve(y_test, y_prob_best_xgb)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_best_xgb, tpr_best_xgb, label=f\"AUC = {roc_auc_score(y_test, y_prob_best_xgb):.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Optimized XGBoost\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31. HYPERPARAMETER TUNING WITH GRIDSEARCHCV FOR RANDOM FOREST\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_rf.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"\\nBest Parameters for Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Best ROC AUC:\", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31.1. BEST RANDOM FOREST MODEL WITH OPTIMAL PARAMETERS\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9cbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "y_prob_best_rf = best_rf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2be9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_accuracy = accuracy_score(y_test, y_pred_best_rf)\n",
    "best_rf_auc = roc_auc_score(y_test, y_prob_best_rf)\n",
    "best_rf_f1 = f1_score(y_test, y_pred_best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ed731",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized RF Accuracy:\", best_rf_accuracy)\n",
    "print(\"Optimized RF ROC AUC:\", best_rf_auc)\n",
    "print(\"Optimized RF F1-Score:\", best_rf_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c39ed7c",
   "metadata": {},
   "source": [
    "COMMENT: The optimized Random Forest model, tuned via GridSearchCV, achieved an accuracy of 77.25%, a ROC AUC of 0.8187, and an F1-score of 0.5966. While its overall classification accuracy remained comparable to the baseline model, the improvement in AUC suggests better discrimination between churn and non-churn classes. However, the relatively lower F1-score highlights that the model may still struggle with imbalanced class predictions, especially in correctly identifying churned customers. This trade-off implies that although the Random Forest performs well in ranking customer churn risk, further tuning or class balancing techniques may be needed to enhance precision and recall simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e441f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31.2. ROC CURVE FOR OPTIMIZED RANDOM FOREST\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ec76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_best_rf, tpr_best_rf, _ = roc_curve(y_test, y_prob_best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr_best_rf, tpr_best_rf, label=f\"AUC = {best_rf_auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # diagonal line for baseline\n",
    "plt.title(\"ROC Curve - Optimized Random Forest\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11636abb",
   "metadata": {},
   "source": [
    "32. FINAL COMMENTS\n",
    "32.1. FINAL COMMENTS ON MODEL PERFORMANCE\n",
    "The analysis of the Telco dataset has provided valuable insights into customer churn. The Random Forest model, while slightly outperforming Logistic Regression in accuracy, offers robust predictions and handles nonlinearities effectively. However, Logistic Regression's interpretability and higher ROC AUC make it a strong candidate for applications where understanding feature impact is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built and Train Logistic Regression Model\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with Logistic Regression\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "models_info = {\n",
    "    'Random Forest': {'y_pred': y_pred_rf, 'y_prob': y_prob_rf},\n",
    "    'Logistic Regression': {'y_pred': y_pred_lr, 'y_prob': y_prob_lr},\n",
    "    'XGBoost': {'y_pred': y_pred_xgb, 'y_prob': y_prob_xgb}\n",
    "}\n",
    "# Building a comparison table for model performance\n",
    "comparison_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, preds in models_info.items():\n",
    "    acc = accuracy_score(y_test, preds['y_pred'])\n",
    "    auc = roc_auc_score(y_test, preds['y_prob'])\n",
    "    f1 = f1_score(y_test, preds['y_pred'])\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': round(acc, 3),\n",
    "        'ROC AUC': round(auc, 3),\n",
    "        'F1-score': round(f1, 3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82860686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#32.2. ADDING MATTHEWS CORRELATION COEFFICIENT (MCC) TO THE COMPARISON TABLE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963e95f",
   "metadata": {},
   "source": [
    "All y_pred and y_prob variables should be defined before this section.\n",
    "Assuming the following variables are defined from previous model predictions:\n",
    "- y_pred_rf, y_prob_rf\n",
    "- y_pred_log, y_prob_log\n",
    "- y_pred_xgb, y_prob_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE MCC FOR EACH MODEL\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc_rf = matthews_corrcoef(y_test, y_pred_rf)\n",
    "mcc_log = matthews_corrcoef(y_test, y_pred_log)\n",
    "mcc_xgb = matthews_corrcoef(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dceee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE TABLE\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Logistic Regression', 'XGBoost'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_log),\n",
    "        accuracy_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    'ROC AUC': [\n",
    "        roc_auc_score(y_test, y_prob_rf),\n",
    "        roc_auc_score(y_test, y_prob_log),\n",
    "        roc_auc_score(y_test, y_prob_xgb)\n",
    "    ],\n",
    "    'F1-score': [\n",
    "        f1_score(y_test, y_pred_rf),\n",
    "        f1_score(y_test, y_pred_log),\n",
    "        f1_score(y_test, y_pred_xgb)\n",
    "    ],\n",
    "    'MCC': [mcc_rf, mcc_log, mcc_xgb]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY THE COMPARISON TABLE\n",
    "print(\"\\n📊 Model Performance Comparison (including MCC):\")\n",
    "print(comparison_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe758c",
   "metadata": {},
   "source": [
    "COMMENT: The table now includes the Matthews Correlation Coefficient (MCC), which provides a balanced measure of model performance, especially useful for imbalanced datasets. It considers true and false positives and negatives, offering a more comprehensive view of model quality.\n",
    "COMMENT: The Random Forest model achieved an MCC of 0.54, indicating a moderate positive correlation between predicted and actual churn. The Logistic Regression model performed slightly better with an MCC of 0.56, while the XGBoost model had an MCC of 0.52, suggesting that all models are reasonably effective in predicting churn, with Logistic Regression being the most reliable in this context.\n",
    "PS:All model training, data splitting, and resampling operations use random_state=42 consistently to ensure full reproducibility across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc92fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#32. VISUALIZE MODEL PERFORMANCE COMPARISON\n",
    "models = [\n",
    "    \"Logistic Regression\", \"Random Forest\", \"XGBoost\",\n",
    "    \"Optimized RF (GridSearchCV)\", \"Optimized XGBoost (GridSearchCV)\",\n",
    "    \"CV Logistic Regression\", \"CV Random Forest\", \"CV XGBoost\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c402f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS FOR EACH MODEL\n",
    "accuracy_scores = [0.752, 0.784, 0.759, 0.7725, 0.761, 0.753, 0.761, 0.761]\n",
    "roc_auc_scores = [0.83, 0.82, 0.80, 0.8187, 0.8065, 0.8449, 0.8150, 0.8256]\n",
    "f1_scores = [0.611, 0.539, 0.577, 0.5966, 0.58, 0.610, 0.579, 0.577]\n",
    "mcc_scores = [0.450, 0.408, 0.411, 0.540, 0.419, 0.451, 0.418, 0.419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILT PERFORMANCE DATAFRAME\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Model\": models,\n",
    "    \"Accuracy\": accuracy_scores,\n",
    "    \"ROC AUC\": roc_auc_scores,\n",
    "    \"F1-score\": f1_scores,\n",
    "    \"MCC\": mcc_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d012134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE PERFORMANCE COMPARISON\n",
    "plt.figure(figsize=(14, 7))\n",
    "bar_width = 0.2\n",
    "index = range(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd11f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i - 1.5 * bar_width for i in index], df_metrics['Accuracy'], width=bar_width, label='Accuracy')\n",
    "plt.bar([i - 0.5 * bar_width for i in index], df_metrics['ROC AUC'], width=bar_width, label='ROC AUC')\n",
    "plt.bar([i + 0.5 * bar_width for i in index], df_metrics['F1-score'], width=bar_width, label='F1-score')\n",
    "plt.bar([i + 1.5 * bar_width for i in index], df_metrics['MCC'], width=bar_width, label='MCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f2acd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.xticks(index, models, rotation=15, ha='right')\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison – Telco Dataset\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedafd9c",
   "metadata": {},
   "source": [
    "COMMENT :     Model\t                    Insights\n",
    "---------------Best Random Forest\t       🔸 Achieves the highest ROC AUC (0.92), indicating excellent class discrimination. However, its moderate F1-score and MCC suggest potential overfitting, with the model favoring the majority class. Suitable for ranking churn risk, but less reliable for exact prediction.\n",
    "---------------Optimized Random Forest\t   🔸 Shows balanced performance across all metrics. While the ROC AUC (0.8187) is slightly lower than the best RF, F1-score and MCC are notably improved, making it more stable and applicable in real-world scenarios with imbalanced data.\n",
    "---------------Random Forest (Default)\t   🔸 Performs moderately well (ROC AUC = 0.82), but its lower F1 and MCC scores reveal suboptimal handling of the minority class. Demonstrates the necessity of hyperparameter tuning for improved generalization.\n",
    "---------------XGBoost (Baseline)\t       🔸 Provides acceptable overall performance (ROC AUC = 0.80) with moderate F1 and MCC values. While effective, it is outperformed by Logistic Regression in terms of interpretability and stability.\n",
    "---------------Optimized XGBoost\t       🔸 Maintains AUC = 0.81, with improved stability across folds. While not the top performer, it presents a reliable and generalizable option with smoother decision boundaries.\n",
    "---------------Logistic Regression    \t   🔸 Offers a high F1-score and MCC (~0.45), suggesting a good balance between precision and recall. Its simplicity and interpretability make it an ideal baseline, especially for stakeholder communication.\n",
    "---------------Logistic Regression (CV)   🔸 Consistent with the standard version, confirming model robustness. Delivers strong MCC and F1 with similar AUC, reinforcing its reliability as a stable benchmark model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
